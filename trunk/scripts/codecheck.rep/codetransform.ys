
/*
 * Source code translator. The idea is to start off with an array
 * of tokens, and then build up parse trees with indices into this
 * array of tokens. The stream of output tokens is set up to be the
 * identical to the input at the start. A grammar can then match the
 * stream of input tokens, and perform replacement operations on
 * the output stream.
 *
 * Rationale: convert syntax of one language to another while preserving
 * the general file structure (including comments!).
 *
 */
DllLoad("pcre"); // We need regular expressions to tokenize the input stream



/*
 * Generic part of parsing for all languages
 */


/*
 * Modification of the output stream based on input and output stream.
 *
 * - 'replace' replaces something in the output stream with the tokens
passed
 *   in. The replacement is on the first token, removing the other tokens
 *   except the comments and spaces.
 * - 'translated', get the already translated part (from the output), so
it can
 *   be inserted somewhere else in the output stream.
 */

10 # EmptyTokens(index_IsPositiveInteger) <-- [CodeTrans'output[index] := {{},Replacement};];
20 # EmptyTokens(index_IsList) <-- [MapSingle("EmptyTokens",index);];

10 # FirstIndex(index_IsPositiveInteger) <-- index;
10 # FirstIndex(index_IsList) 
   <-- 
   [
     index:=Flatten(index,"List");
     index:=Select("IsPositiveInteger",index);
     index[1];
   ];

10 # LastIndex(index_IsPositiveInteger) <-- index;
10 # LastIndex(index_IsList) 
   <-- 
   [
     index:=Flatten(index,"List");
     index[Length(index)];
   ];


10 # replace(index_IsPositiveInteger,tokens_IsList) 
   <-- 
[ 
  CodeTrans'output[index] := {tokens,Replacement};
];
20 # replace(index_IsList,tokens_IsList) 
   <-- 
[
  EmptyTokens(index);
  CodeTrans'output[FirstIndex(index)] := {tokens,Replacement};
]; 
10 # translated(index_IsPositiveInteger) <-- CodeTrans'output[index][1];
10 # translated(index_IsList) <-- MapSingle("translated",index);

ReportParseError(errorString, tokenId) :=
[
  Local(rest);
  Set(rest, CodeTrans'input[tokenId][1]);
  if (Length(rest)>50)
  [
    rest:=StringMid(1,50,rest):"...";
  ];
  ToString()[Echo(errorString," in file ",TokenFile(tokenId)," at line ",TokenLine(tokenId),":",rest);];
];

/*
 * Read tokens from input
 */
ReadTokens(language):=
[
  Local(token,result,currentfile,currentline,tokenmap);
  result:={};
  currentfile:=CurrentFile();
  currentline:=CurrentLine();
  Set(token,PcreNextToken());
  While (token != EndOfFile)
  [
    If(Head(Tail(token)) != UnParsed,
    [
      Local(str);
      str:=token[1];
      If(Length(str)>100,str:=StringMid(1,100,str):"...");
      Check(Head(Tail(token)) != UnParsed,"UnRecognized token in file ":currentfile:" at line ":String(currentline):" : ":str);
    ]);
    // Tag the line the token was read from to the token.
    Set(token,FlatCopy(token));
    DestructiveAppend(token,currentfile);
    DestructiveAppend(token,currentline);
    // Add the token to the list of resulting tokens.
    DestructiveInsert(result,1,token);
    // Read in the next token.
    Set(currentline,CurrentLine());
    Set(token,PcreNextToken());
  ];
  // Finished. Return result.
  result := DestructiveReverse(result);

//Echo(result);
  result;
];

/*
 * Write tokens to output
 */
10 # WriteSingleToken(tokens_IsList)
   <-- ForEach(item,tokens)WriteSingleToken(item);
20 # WriteSingleToken(s_IsString) <-- WriteString(s);
30 # WriteSingleToken(_rest) 
   <-- 
[
Echo("Rest is ",rest);
  Check(False,"Incomprehensible token in output");
];
WriteTokens(tokens):= 
[
//Echo("output is ",tokens);
  ForEach(item,tokens) WriteSingleToken(item[1]);
];

TokenFile(index) := CodeTrans'input[index][3];
TokenLine(index) := CodeTrans'input[index][4];


/*
 * Given a set of indices into the array of tokens, return the tokens
themselves
 */
10 # GetInputTokens(i_IsInteger) <-- CodeTrans'input[i][1];
20 # GetInputTokens(list_IsList) <-- MapSingle("GetInputTokens",list);
30 # GetInputTokens(_i) <-- i;

/* Default post processor, with two routines as parameters: one to get the expression
   ahd the second to process it.
 */
DefaultPostProcess(getExpression,process):=
[
  Local(nrInputTokens);
  nrInputTokens:=Length(CodeTrans'input);
  tokenIndex:=0;
  NextToken();
  While(tokenIndex < nrInputTokens)
  [
    Local(expression);
//Echo("TRYING ");
    expression := Apply(getExpression,{});
//Echo({expression});
//Echo({GetInputTokens(expression)});
    Apply(process,{GetInputTokens(expression),expression});
  ];
];


/*
 * Scan file, convert source and output result to current output.
 */
CodeTransform(language,action) :=
[
  // set up the tokens to read the language at hand
  PcreLexer(Eval(Atom(language:"'Tokens"))); 
  // read all the tokens from the current input stream into a list
  CodeTrans'input := ReadTokens(language);
  // During the pre-processing stage one is still allowed to change the number of input
  // tokens. This is not the case later on, as the input stream is copied to the output
  // stream after pre-processing, and the number of tokens in the input and output stream
  // should stay the same.
  Apply(language:"'":action:"'PreProcess",{});
  // copy the input stream to the outpur stream
//Echo(CodeTrans'input);
  CodeTrans'output:=ArrayCreateFromList(CodeTrans'input);
  CodeTrans'input:=ArrayCreateFromList(CodeTrans'input);
  // post-process, converting the tokens in the output stream based on the tokens in the input stream
  Apply(language:"'":action:"'PostProcess",{});
  // write the resulting output stream to the current output
  Apply(language:"'":action:"'EmitCode",{});

  True;
];

/* TranslatedExpression gets the internal representation given the string.
 */
TranslatedExpression(language, grammar, string):=
[
  FromString(string)
  [
    // set up the tokens to read the language at hand
    PcreLexer(Eval(Atom(language:"'Tokens"))); 
    // read all the tokens from the current input stream into a list
    CodeTrans'input := ReadTokens(language);
    // Get the expression
    Local(nrInputTokens);
    nrInputTokens:=Length(CodeTrans'input);
    tokenIndex:=0;
    NextToken();
    Apply(language:"'GetExpression",{grammar});
  ];  
];

/** WithApply should evaluate using a specific apply operation. 
 * TODO move to generic code base?
 */
Macro()WithApply(operation,expression);
LocalSymbols(ex,args,exlist,op,i,arg)
[
  10 # WithApply(_operation,_expression) 
    <--
    [
      Local(ex);
      Set(ex,@expression);
      If(IsAtom(ex),
      [
        Apply((@operation),{@expression});
      ],
      [
        Local(args,exlist,op,i,arg);
        Set(op,@operation);
        Set(exlist,Listify(@expression));
        Set(args,FillList(0,Length(exlist)));
        args[1] := exlist[1];
        For (i:=2,i<=Length(exlist),i++)
        [
          Set(arg,exlist[i]);
          args[i]:= `WithApply(@op,@arg);
        ];
        Apply((@operation),{UnList(args)});
      ]);
    ];


  10 # WithApplyTwoLists(_operation,list1_IsList,list2_IsList) 
    <--
    [
      If(IsAtom(list1),
      [
        Apply(operation,{list1,list2});
      ],
      [
        Local(i);
        For (i:=2,i<=Length(list1),i++)
        [
          WithApplyTwoLists(operation,list1[i],list2[i]);
        ];
        Apply(operation,{list1,list2});
      ]);
    ];

];

100 # WithApply(_operation,_rest) 
    <--
    [
      Echo("Failed on ",rest);
      Check(False,"failed");
    ]; 



10 # PatternNames(match(_var)) <-- _Atom(String(var):"Name");
10 # PatternNames(match(_var,_pred)) <-- Atom(String(var):"Name")_pred;
20 # PatternNames(i_IsInteger) <-- GetInputTokens(i);
100 # PatternNames(_rest) <-- rest;

10  # PatternIds(match(_var)) <-- _Atom(String(var):"Id");
10  # PatternIds(match(_var,_pred)) <-- Atom(String(var):"Id")_pred;
20  # PatternIds(i_IsInteger) <-- _Atom("ids":String(i));
100 # PatternIds(_rest) <-- rest;


RegexTest(language,grammar,pat,exp):=
[
  Set(pat,TranslatedExpression(language,grammar,pat));
  Set(pat,`WithApply("PatternIds",pat));
Echo("Pattern    is ",pat);
  Set(exp,TranslatedExpression(language,grammar,exp));
Echo("Expression is ",GetInputTokens(exp));
  Local(u);
  u:=PatternCreate(F(pat),True);
  PatternMatches(u,F(exp));  
];

Bodied("Recognize",0);
Macro(Recognize,{language,grammar,pred,rulebase,string,body})
[
  Local(expr,pr,rb,names,ids,bd);
  Set(expr,TranslatedExpression(@language,@grammar,@string));

  Set(pr,@pred);
  Set(rb,Atom(@rulebase));
  Set(names,`WithApply("PatternNames",@expr));
  Set(ids  ,`WithApply("PatternIds",@expr));
//Echo("In ",rb);
//Echo("  string = ",@string);
//Echo("  names = ",names);
//Echo("  ids = ",ids);
  Set(bd,Hold(@body));

//Echo(`Hold((@pr) # @rb(@names,@ids) <-- (@bd)));

//  `((@pr) # @rb(@names,@ids) <-- (@bd));
  `((@pr) # (@rb(@names,@ids))_([(@bd);False;]) <-- True);
];

